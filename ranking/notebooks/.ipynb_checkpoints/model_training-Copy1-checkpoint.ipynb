{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372a81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple, Union, Callable\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from langdetect import detect\n",
    "import faiss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f8b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from lib.ranking import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2cdcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b3264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f48441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../../ranking and matching/final_project/data'\n",
    "\n",
    "glue_qqp_dir = PATH + '/QQP'\n",
    "glove_path = PATH + '/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d9c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(glove_path,\n",
    "              glue_qqp_dir,\n",
    "              min_token_occurancies = 1,\n",
    "              knrm_kernel_num = 21,\n",
    "              knrm_out_mlp = [10, 5],\n",
    "              dataloader_bs = 1024,\n",
    "              freeze_knrm_embeddings = False,\n",
    "              train_lr = 0.01,\n",
    "              change_train_loader_ep = 10,\n",
    "              n_training = 12000,\n",
    "              )\n",
    "\n",
    "model.initialize_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e25132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5653442646777981\n",
      "5 0.8986491445062015\n",
      "10 0.9291317588355423\n",
      "15 0.939217092741588\n",
      "20 0.9452734667065634\n",
      "25 0.9491157158382607\n",
      "29 0.9507637693795155\n",
      "CPU times: user 6min 51s, sys: 1min 35s, total: 8min 26s\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model training\n",
    "\n",
    "model.train(30)\n",
    "\n",
    "state_mlp = model.model.mlp.state_dict()\n",
    "torch.save(state_mlp, open('../artifacts/knrm/knrm_mlp.bin', 'wb'))\n",
    "\n",
    "state_emb = model.model.embeddings.state_dict()\n",
    "torch.save(state_emb, open('../artifacts/knrm/knrm_emb.bin', 'wb'))\n",
    "\n",
    "with open('../artifacts/knrm/vocab.json', 'w') as f:\n",
    "    json.dump(model.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fa566",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f4ed573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.index import Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a25c8f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of documents: 493874\n"
     ]
    }
   ],
   "source": [
    "df = model.glue_train_df\n",
    "df = df.loc[:, ['text_left', 'text_right']].stack()\n",
    "df.drop_duplicates(inplace=True)\n",
    "all_documents = {str(i): t for i, t in enumerate(df.values)}\n",
    "print(f'n of documents: {len(all_documents)}')\n",
    "\n",
    "with open('../artifacts/all_documents.json', 'w') as f:\n",
    "    json.dump(all_documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ebbd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"EMB_PATH_KNRM\"] = '../artifacts/knrm/knrm_emb.bin'\n",
    "os.environ[\"MLP_PATH\"] = '../artifacts/knrm/knrm_mlp.bin'\n",
    "os.environ[\"EMB_PATH_GLOVE\"] = glove_path\n",
    "os.environ[\"VOCAB_PATH\"] = '../artifacts/knrm/vocab.json'\n",
    "\n",
    "EMB_PATH_KNRM = os.environ[\"EMB_PATH_KNRM\"]\n",
    "MLP_PATH = os.environ[\"MLP_PATH\"]\n",
    "EMB_PATH_GLOVE = os.environ[\"EMB_PATH_GLOVE\"]\n",
    "VOCAB_PATH = os.environ[\"VOCAB_PATH\"]\n",
    "\n",
    "model = Model(EMB_PATH_GLOVE,\n",
    "              EMB_PATH_GLOVE,\n",
    "              min_token_occurancies = 1,\n",
    "              knrm_kernel_num = 21,\n",
    "              knrm_out_mlp = [10, 5],\n",
    "              train_lr = 0.01,\n",
    "              )\n",
    "\n",
    "state_dict = torch.load(EMB_PATH_KNRM) \n",
    "emb_matrix = state_dict['weight']\n",
    "mlp_state_dict = torch.load(MLP_PATH)\n",
    "model.build_model_with_pretrained_weights(mlp_state_dict, emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e04db8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 793 ms, total: 30.4 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selection = Selection(glove_path, agg_method='mean', metric='l2')\n",
    "selection.init_index(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f54b4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simmilar_questions(query):\n",
    "    ids, texts = selection.search(query)\n",
    "    model_input = model.prediction_data(query, texts, vocab)\n",
    "    res = model.knrm.predict(model_input)\n",
    "    _, I = torch.sort(res.flatten(), descending=True)\n",
    "    I = I[:10] \n",
    "    texts_out = [texts[i] for i in I]\n",
    "    ids_out = [ids[i] for i in I]\n",
    "    return texts_out, ids_out\n",
    "\n",
    "query = 'What are the most lovely self help book I should read?'\n",
    "texts_out, ids_out = get_simmilar_questions(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bb6e7ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the top self help books I should read?\n",
      "What are the best self-help books you've ever read?\n",
      "What are some books I should read this summer?\n",
      "What book have you re-read the most, and why?\n",
      "What are the books to be read for self improvement?\n",
      "What are the best books one should read?\n",
      "What are the best books that one should must read?\n",
      "What are some good book that are a must read?\n",
      "What is the most important book you have ever read?\n",
      "What are some of the best novels everyone should read?\n"
     ]
    }
   ],
   "source": [
    "for q in texts_out:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c66ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hard_ml",
   "language": "python",
   "name": "hard_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
